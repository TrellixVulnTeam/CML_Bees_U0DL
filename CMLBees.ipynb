{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a8b126-00d3-405c-b693-d09974d93a23",
   "metadata": {},
   "source": [
    "## CML Bees - Simplifying SageMaker Object Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633fb505-581e-49f3-aeb7-d8a9e78911c8",
   "metadata": {},
   "source": [
    "### Running 1 - Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d514b3e-c33a-4cd3-a588-a708d8cde09d",
   "metadata": {},
   "source": [
    "#### 1_prepare_data/docker/code/utils/tf_record_util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e505a791-2e95-439c-b0aa-499730286f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import jsonlines\n",
    "import random\n",
    "import logging\n",
    "#from utils import dataset_util\n",
    "from TensorFlow.models.research.object_detection.utils import dataset_util\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "205f585f-e861-4848-80ee-94b64b8275b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfRecordGenerator:\n",
    "    def __init__(self, image_dir, manifest, label_map, output_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.manifest = manifest\n",
    "        self.label_map = label_map\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    def generate_tf_records(self):\n",
    "        with jsonlines.open(self.manifest, 'r') as reader:\n",
    "            ground_truth_annotations = list(reader)\n",
    "            dataset = split_dataset(ground_truth_annotations)\n",
    "            for subset in dataset:\n",
    "                logging.info(f'GENERATING TF RECORD FOR {subset}')\n",
    "                writer = tf.io.TFRecordWriter(os.path.join(self.output_dir, f'{subset}.records'))\n",
    "                for image_annotations in dataset[subset]:\n",
    "                    annotation_dict = json.loads(json.dumps(image_annotations))\n",
    "                    tf_example = self._create_tf_example(annotation_dict['source-ref'],\n",
    "                                                         annotation_dict['bees-500']['annotations'])\n",
    "                    writer.write(tf_example.SerializeToString())\n",
    "                writer.close()\n",
    "\n",
    "    def _create_tf_example(self, s3_image_path, image_dir, annotations):\n",
    "        image_name = os.path.basename(s3_image_path)\n",
    "        image_path = f'{self.image_dir}/{image_name}'\n",
    "        im = Image.open(image_path)\n",
    "\n",
    "        # READ IMAGE FILE\n",
    "        with tf.io.gfile.GFile(image_path, 'rb') as fid:\n",
    "            encoded_jpg = fid.read()\n",
    "\n",
    "        encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "        encoded_jpg_io.seek(0)\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "        image_width, image_height = image.size\n",
    "        if image.format != 'JPEG':\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "        xmins = []\n",
    "        ymins = []\n",
    "        xmaxs = []\n",
    "        ymaxs = []\n",
    "        classes = []\n",
    "        classes_text = []\n",
    "        for a in annotations:\n",
    "            x = a['left']\n",
    "            y = a['top']\n",
    "            width = a['width']\n",
    "            height = a['height']\n",
    "            class_id = a['class_id']\n",
    "            xmins.append(float(x) / image_width)\n",
    "            xmaxs.append(float(x + width) / image_width)\n",
    "            ymins.append(float(y) / image_height)\n",
    "            ymaxs.append(float(y + height) / image_height)\n",
    "            class_name = self.label_map[int(class_id)]\n",
    "            classes_text.append(class_name.encode('utf8'))\n",
    "            classes.append(class_id)\n",
    "\n",
    "        feature_dict = {\n",
    "            'image/height': dataset_util.int64_feature(image_height),\n",
    "            'image/width': dataset_util.int64_feature(image_width),\n",
    "            'image/filename': dataset_util.bytes_feature(bytes(image_name, 'utf-8')),\n",
    "            'image/source_id': dataset_util.bytes_feature(bytes(image_name.replace('.jpg', ''), 'utf-8')),\n",
    "            'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "            'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "            'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "            'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "            'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "            'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "            'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "            'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "        }\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c91a57f-fa9c-48ed-96b6-b8a04cab23a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(list_images):\n",
    "    dataset = {}\n",
    "    random.seed(42)\n",
    "    random.shuffle(list_images)\n",
    "    num_train = int(0.9 * len(list_images))\n",
    "    dataset['train'] = list_images[:num_train]\n",
    "    dataset['validation'] = list_images[num_train:]\n",
    "    logging.info(f'TRAINING EXAMPLES: %d - VALIDATION EXAMPLES: %d', len(dataset['train']), len(dataset['validation']))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a69be-a004-4467-8d2a-b5bc5ed0335e",
   "metadata": {},
   "source": [
    "#### 1_prepare_data/docker/code/prepare_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed514e31-9ea2-4b42-a6fc-bd63a48aeb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tf_record_util_copy import TfRecordGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ca2cfa0-85a9-48c3-b108-1202ca2e7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/home/cdsw/data/data'\n",
    "ground_truth_manifest = '/home/cdsw/data/data/output.manifest'\n",
    "label_map = '{\"0\": \"bee\"}' # class mapping here - e.g. - each class ID should map to the human readable equivalent\n",
    "output_folder = '/home/cdsw/data/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa1184ef-4140-40da-b72c-36edc93c66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(input_folder, ground_truth_manifest, label_map, output_folder):\n",
    "    \n",
    "    label_map = json.loads(args.label_map)\n",
    "\n",
    "    # Feed in necessary path variables from above operations\n",
    "    tf_record_generator = TfRecordGenerator(image_dir=input_folder,\n",
    "                                            manifest=ground_truth_manifest,\n",
    "                                            label_map=label_map,\n",
    "                                            output_dir=output_folder)\n",
    "\n",
    "    print('GENERATING TF RECORD FILES')\n",
    "    tf_record_generator.generate_tf_records()\n",
    "\n",
    "    print('GENERATING LABEL MAP FILE')\n",
    "    with open(f'{output_folder}/label_map.pbtxt', 'w') as label_map_file:\n",
    "        for item in label_map:\n",
    "            label_map_file.write('item {\\n')\n",
    "            label_map_file.write(' id: ' + str(int(item) + 1) + '\\n')\n",
    "            label_map_file.write(\" name: '\" + label_map[item] + \"'\\n\")\n",
    "            label_map_file.write('}\\n\\n')\n",
    "\n",
    "    print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f12627e-439a-4f93-8fa7-d27488e2552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = json.loads(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e53f018-eaf2-45bc-ac75-e0788dd03f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed in necessary path variables from above operations\n",
    "tf_record_generator = TfRecordGenerator(image_dir=input_folder,\n",
    "                                        manifest=ground_truth_manifest,\n",
    "                                        label_map=label_map,\n",
    "                                        output_dir=output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "479780c9-1c63-4f0b-8a13-8e083a602de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING TF RECORD FILES\n"
     ]
    }
   ],
   "source": [
    "print('GENERATING TF RECORD FILES')\n",
    "tf_record_generator.generate_tf_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a83cdcff-0ea2-48b9-a756-dd3b0a7dfdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING LABEL MAP FILE\n"
     ]
    }
   ],
   "source": [
    "print('GENERATING LABEL MAP FILE')\n",
    "with open(f'{output_folder}/label_map.pbtxt', 'w') as label_map_file:\n",
    "    for item in label_map:\n",
    "        label_map_file.write('item {\\n')\n",
    "        label_map_file.write(' id: ' + str(int(item) + 1) + '\\n')\n",
    "        label_map_file.write(\" name: '\" + label_map[item] + \"'\\n\")\n",
    "        label_map_file.write('}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d3cce-341c-407c-9219-cbd640a8b343",
   "metadata": {},
   "source": [
    "### Train model 2 - Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368dfb12-ef32-43dd-9a17-4f78acf2ff15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
